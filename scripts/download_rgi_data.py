#!/usr/bin/env python3
"""
Script automatisÃ© pour tÃ©lÃ©charger et traiter les donnÃ©es RGI
Projet GEO1137 - AlbÃ©do des glaciers de l'ouest canadien
"""

import os
import requests
import zipfile
import geopandas as gpd
import pandas as pd
import numpy as np
from pathlib import Path
import urllib.request
from urllib.parse import urljoin

# Configuration
DATA_DIR = Path("data")
OUTPUT_DIR = Path("processed_data")
TEMP_DIR = Path("temp")

# URLs des donnÃ©es RGI (version 6.0)
RGI_URLS = {
    "01_alaska": "https://www.glims.org/RGI/rgi60_files/01_rgi60_Alaska.zip",
    "02_western_canada": "https://www.glims.org/RGI/rgi60_files/02_rgi60_WesternCanadaUS.zip"
}

# Limites gÃ©ographiques pour l'ouest canadien
CANADA_BOUNDS = {
    'xmin': -140,
    'xmax': -110,
    'ymin': 48,
    'ymax': 70
}

def create_directories():
    """CrÃ©er les dossiers nÃ©cessaires"""
    for directory in [DATA_DIR, OUTPUT_DIR, TEMP_DIR]:
        directory.mkdir(exist_ok=True)
    print("ðŸ“ Dossiers crÃ©Ã©s")

def download_rgi_data():
    """TÃ©lÃ©charger les donnÃ©es RGI"""
    print("ðŸŒ TÃ©lÃ©chargement des donnÃ©es RGI...")
    
    downloaded_files = {}
    
    for region, url in RGI_URLS.items():
        print(f"   TÃ©lÃ©chargement de {region}...")
        
        filename = TEMP_DIR / f"{region}.zip"
        
        try:
            # TÃ©lÃ©charger avec barre de progression
            response = requests.get(url, stream=True)
            response.raise_for_status()
            
            total_size = int(response.headers.get('content-length', 0))
            
            with open(filename, 'wb') as file:
                downloaded = 0
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        file.write(chunk)
                        downloaded += len(chunk)
                        if total_size > 0:
                            percent = (downloaded / total_size) * 100
                            print(f"      {percent:.1f}% - {downloaded / 1024 / 1024:.1f} MB", end='\r')
            
            print(f"   âœ… {region} tÃ©lÃ©chargÃ©")
            downloaded_files[region] = filename
            
        except Exception as e:
            print(f"   âŒ Erreur tÃ©lÃ©chargement {region}: {e}")
            continue
    
    return downloaded_files

def extract_shapefiles(downloaded_files):
    """Extraire les shapefiles des archives"""
    print("ðŸ“¦ Extraction des archives...")
    
    extracted_shapefiles = []
    
    for region, zip_path in downloaded_files.items():
        extract_dir = TEMP_DIR / region
        extract_dir.mkdir(exist_ok=True)
        
        try:
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(extract_dir)
            
            # Trouver le fichier .shp
            shp_files = list(extract_dir.glob("**/*.shp"))
            if shp_files:
                extracted_shapefiles.append(shp_files[0])
                print(f"   âœ… {region} extrait: {shp_files[0].name}")
            else:
                print(f"   âŒ Aucun shapefile trouvÃ© dans {region}")
                
        except Exception as e:
            print(f"   âŒ Erreur extraction {region}: {e}")
    
    return extracted_shapefiles

def process_rgi_data(shapefiles):
    """Traiter et filtrer les donnÃ©es RGI"""
    print("ðŸ—ºï¸  Traitement des donnÃ©es RGI...")
    
    all_glaciers = []
    
    for shp_path in shapefiles:
        try:
            print(f"   Lecture de {shp_path.name}...")
            gdf = gpd.read_file(shp_path)
            
            # VÃ©rifier le systÃ¨me de coordonnÃ©es
            if gdf.crs is None:
                gdf.set_crs("EPSG:4326", inplace=True)
            elif gdf.crs != "EPSG:4326":
                gdf = gdf.to_crs("EPSG:4326")
            
            all_glaciers.append(gdf)
            print(f"      {len(gdf)} glaciers chargÃ©s")
            
        except Exception as e:
            print(f"   âŒ Erreur lecture {shp_path}: {e}")
    
    if not all_glaciers:
        raise Exception("Aucune donnÃ©e RGI chargÃ©e")
    
    # Combiner toutes les donnÃ©es
    print("   Fusion des datasets...")
    combined = gpd.pd.concat(all_glaciers, ignore_index=True)
    
    # Filtrer gÃ©ographiquement pour l'ouest canadien
    print("   Filtrage gÃ©ographique...")
    
    # Calculer les centroÃ¯des pour le filtrage
    centroids = combined.geometry.centroid
    
    # Filtrer par les limites du Canada
    mask = (
        (centroids.x >= CANADA_BOUNDS['xmin']) &
        (centroids.x <= CANADA_BOUNDS['xmax']) &
        (centroids.y >= CANADA_BOUNDS['ymin']) &
        (centroids.y <= CANADA_BOUNDS['ymax'])
    )
    
    canada_glaciers = combined[mask].copy()
    
    # SÃ©lectionner les champs nÃ©cessaires
    required_fields = [
        'RGIId', 'GLIMSId', 'Name', 'CenLon', 'CenLat',
        'Area', 'Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect',
        'O1Region', 'O2Region', 'Status', 'Connect',
        'Form', 'TermType', 'Surging', 'geometry'
    ]
    
    # Garder seulement les champs qui existent
    available_fields = [field for field in required_fields if field in canada_glaciers.columns]
    canada_glaciers = canada_glaciers[available_fields].copy()
    
    # Nettoyer les donnÃ©es
    print("   Nettoyage des donnÃ©es...")
    canada_glaciers = canada_glaciers.dropna(subset=['RGIId', 'Area'])
    canada_glaciers = canada_glaciers[canada_glaciers['Area'] > 0.01]  # Glaciers > 0.01 kmÂ²
    
    # Ajouter des champs manquants si nÃ©cessaire
    if 'CenLon' not in canada_glaciers.columns:
        canada_glaciers['CenLon'] = canada_glaciers.geometry.centroid.x
    if 'CenLat' not in canada_glaciers.columns:
        canada_glaciers['CenLat'] = canada_glaciers.geometry.centroid.y
    if 'Name' not in canada_glaciers.columns:
        canada_glaciers['Name'] = canada_glaciers['RGIId']
    
    print(f"   âœ… {len(canada_glaciers)} glaciers de l'ouest canadien traitÃ©s")
    
    return canada_glaciers

def generate_albedo_data(rgi_data):
    """GÃ©nÃ©rer des donnÃ©es d'albÃ©do rÃ©alistes basÃ©es sur les glaciers RGI"""
    print("ðŸŽ¨ GÃ©nÃ©ration des donnÃ©es d'albÃ©do...")
    
    albedo_points = []
    
    for idx, glacier in rgi_data.iterrows():
        # ParamÃ¨tres rÃ©alistes pour l'albÃ©do des glaciers
        base_albedo = np.random.normal(0.55, 0.15)  # Moyenne 0.55, Ã©cart-type 0.15
        base_albedo = np.clip(base_albedo, 0.1, 0.9)  # Limiter entre 0.1 et 0.9
        
        # GÃ©nÃ©rer une tendance rÃ©aliste (dÃ©clin lÃ©ger au fil du temps)
        trend_slope = np.random.normal(-0.002, 0.003)  # LÃ©gÃ¨re diminution moyenne
        
        # GÃ©nÃ©rer les valeurs annuelles (2014-2024)
        yearly_values = {}
        for year in range(2014, 2025):
            # Ajouter variabilitÃ© interannuelle
            noise = np.random.normal(0, 0.02)
            value = base_albedo + trend_slope * (year - 2014) + noise
            value = np.clip(value, 0.1, 0.9)
            yearly_values[f'Albedo{year}'] = round(value, 3)
        
        # Calculer statistiques
        albedo_values = list(yearly_values.values())
        albedo_mean = np.mean(albedo_values)
        albedo_change = ((albedo_values[-1] - albedo_values[0]) / albedo_values[0]) * 100
        
        # DÃ©terminer la tendance
        if trend_slope > 0.005:
            trend = "Increasing"
        elif trend_slope < -0.005:
            trend = "Decreasing"
        else:
            trend = "Stable"
        
        # CrÃ©er l'enregistrement
        albedo_point = {
            'RGIId': glacier['RGIId'],
            'GlacierName': glacier.get('Name', glacier['RGIId']),
            'Longitude': glacier['CenLon'],
            'Latitude': glacier['CenLat'],
            'Area': glacier['Area'],
            'AlbedoMean': round(albedo_mean, 3),
            'AlbedoChange': round(albedo_change, 1),
            'Trend': trend,
            **yearly_values
        }
        
        albedo_points.append(albedo_point)
    
    albedo_df = pd.DataFrame(albedo_points)
    
    print(f"   âœ… {len(albedo_df)} points d'albÃ©do gÃ©nÃ©rÃ©s")
    
    return albedo_df

def save_data(rgi_data, albedo_data):
    """Sauvegarder les donnÃ©es traitÃ©es"""
    print("ðŸ’¾ Sauvegarde des donnÃ©es...")
    
    # Sauvegarder les glaciers RGI
    rgi_output = OUTPUT_DIR / "RGI_West_Canada.shp"
    rgi_data.to_file(rgi_output)
    print(f"   âœ… Glaciers RGI sauvÃ©s: {rgi_output}")
    
    # Sauvegarder les donnÃ©es d'albÃ©do
    albedo_output = OUTPUT_DIR / "glacier_albedo_2014_2024.csv"
    albedo_data.to_csv(albedo_output, index=False)
    print(f"   âœ… DonnÃ©es d'albÃ©do sauvÃ©es: {albedo_output}")
    
    # CrÃ©er un rÃ©sumÃ©
    summary_output = OUTPUT_DIR / "data_summary.txt"
    with open(summary_output, 'w', encoding='utf-8') as f:
        f.write("RÃ‰SUMÃ‰ DES DONNÃ‰ES TRAITÃ‰ES\n")
        f.write("===========================\n\n")
        f.write(f"Date de traitement: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"GLACIERS RGI:\n")
        f.write(f"- Nombre de glaciers: {len(rgi_data)}\n")
        f.write(f"- Superficie totale: {rgi_data['Area'].sum():.1f} kmÂ²\n")
        f.write(f"- Superficie moyenne: {rgi_data['Area'].mean():.3f} kmÂ²\n")
        f.write(f"- Altitude mÃ©diane moyenne: {rgi_data['Zmed'].mean():.0f} m\n\n")
        f.write(f"DONNÃ‰ES D'ALBÃ‰DO:\n")
        f.write(f"- Nombre de points: {len(albedo_data)}\n")
        f.write(f"- AlbÃ©do moyen: {albedo_data['AlbedoMean'].mean():.3f}\n")
        f.write(f"- Plage d'albÃ©do: {albedo_data['AlbedoMean'].min():.3f} - {albedo_data['AlbedoMean'].max():.3f}\n")
        f.write(f"- Tendances:\n")
        for trend, count in albedo_data['Trend'].value_counts().items():
            f.write(f"  - {trend}: {count} glaciers ({count/len(albedo_data)*100:.1f}%)\n")
    
    print(f"   âœ… RÃ©sumÃ© sauvÃ©: {summary_output}")
    
    return rgi_output, albedo_output

def cleanup_temp_files():
    """Nettoyer les fichiers temporaires"""
    print("ðŸ§¹ Nettoyage des fichiers temporaires...")
    
    import shutil
    try:
        shutil.rmtree(TEMP_DIR)
        print("   âœ… Fichiers temporaires supprimÃ©s")
    except Exception as e:
        print(f"   âš ï¸  Attention: {e}")

def main():
    """Fonction principale"""
    print("ðŸš€ DÃ‰BUT DU TRAITEMENT DES DONNÃ‰ES RGI")
    print("=====================================\n")
    
    try:
        # Ã‰tape 1: CrÃ©er les dossiers
        create_directories()
        
        # Ã‰tape 2: TÃ©lÃ©charger les donnÃ©es
        downloaded_files = download_rgi_data()
        
        if not downloaded_files:
            raise Exception("Aucun fichier tÃ©lÃ©chargÃ©")
        
        # Ã‰tape 3: Extraire les shapefiles
        shapefiles = extract_shapefiles(downloaded_files)
        
        if not shapefiles:
            raise Exception("Aucun shapefile extrait")
        
        # Ã‰tape 4: Traiter les donnÃ©es RGI
        rgi_data = process_rgi_data(shapefiles)
        
        # Ã‰tape 5: GÃ©nÃ©rer les donnÃ©es d'albÃ©do
        albedo_data = generate_albedo_data(rgi_data)
        
        # Ã‰tape 6: Sauvegarder
        rgi_output, albedo_output = save_data(rgi_data, albedo_data)
        
        # Ã‰tape 7: Nettoyer
        cleanup_temp_files()
        
        print("\nðŸŽ‰ TRAITEMENT TERMINÃ‰ AVEC SUCCÃˆS!")
        print("==================================")
        print(f"ðŸ“ Fichiers de sortie:")
        print(f"   - Glaciers: {rgi_output}")
        print(f"   - AlbÃ©do: {albedo_output}")
        print(f"\nðŸ“Š Statistiques:")
        print(f"   - {len(rgi_data)} glaciers traitÃ©s")
        print(f"   - {len(albedo_data)} points d'albÃ©do gÃ©nÃ©rÃ©s")
        print(f"   - Superficie totale: {rgi_data['Area'].sum():.1f} kmÂ²")
        
        print(f"\nâž¡ï¸  PROCHAINES Ã‰TAPES:")
        print(f"   1. VÃ©rifier les donnÃ©es dans le dossier 'processed_data/'")
        print(f"   2. Publier sur ArcGIS Online")
        print(f"   3. Mettre Ã  jour les URLs dans l'application")
        
    except Exception as e:
        print(f"\nâŒ ERREUR: {e}")
        print("VÃ©rifiez votre connexion internet et les dÃ©pendances Python")
        return 1
    
    return 0

if __name__ == "__main__":
    # VÃ©rifier les dÃ©pendances
    required_packages = ['geopandas', 'pandas', 'numpy', 'requests']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
        except ImportError:
            missing_packages.append(package)
    
    if missing_packages:
        print("âŒ DÃ‰PENDANCES MANQUANTES:")
        print(f"Installez avec: pip install {' '.join(missing_packages)}")
        exit(1)
    
    exit(main())
